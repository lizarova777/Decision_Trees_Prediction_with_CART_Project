---
title: "Lizarov,Anna.Assignment#5"
author: "Anna Lizarov"
date: "November 13, 2018"
output: html_document
---

Data from the Assistments Intelligent Tutoring system will be used for the analysis. This system gives students hints based on how they perform on math problems. 

# Call Libraries
```{r}
library(rpart)
library(party)
```
## Part I

```{r}
(D1 <- read.csv("intelligent_tutor.csv", header=TRUE))
```

#Classification Tree
First we will build a classification tree to predict which students ask a teacher for help, which start a new session, or which give up, based on whether or not the student completed a session (D1$complete) and whether or not they asked for hints (D1$hint.y). 
```{r}
c.tree <- rpart(action ~ hint.y + complete, method="class", data=D1) #Notice the standard R notion for a formula X ~ Y

#Look at the error of this tree
printcp(c.tree)
```
```{r}
#Plot the tree
post(c.tree, file = "tree.ps", title = "Session Completion Action: 1 - Ask teacher, 2 - Start new session, 3 - Give up")
```


## Part II

#Regression Tree

We want to see if we can build a decision tree to help teachers decide which students to follow up with, based on students' performance in Assistments. We will create three groups ("teacher should intervene", "teacher should monitor student progress" and "no action") based on students' previous use of the system and how many hints they use. To do this we will be building a decision tree using the "party" package. The party package builds decision trees based on a set of statistical stopping rules.

#Take a look at our outcome variable "score"
```{r}
hist(D1$score)
```

#Create a categorical outcome variable based on student score to advise the teacher using an "ifelse" statement
```{r}
D1$advice <- ifelse(D1$score <=0.4, "intervene", ifelse(D1$score > 0.4 & D1$score <=0.8, "monitor", "no action"))
```

#Build a decision tree that predicts "advice" based on how many problems students have answered before, the percentage of those problems they got correct and how many hints they required
```{r}
score_ctree <- ctree(factor(advice) ~ prior_prob_count + prior_percent_correct + hints, D1)
```

#Plot tree
```{r}
plot(score_ctree)
```

#Interpretation:
```{r}
#Answer: The first behavior that the teacher should pay close attention to the when the student is requesting at most 12 hints and answered less than 63% of problems correctly before the current session, and scored less than 81%. The second behavior is when a student asked for more than 12 hints and still scored less than 81%. In particular, for node 7, 60% of the students are classified into "monitor" group and 30% of the students are placed into "intervene" group. Likewise, for node 9, 60% of the students are classified into "monitor" group and 40% of the students are placed into "intervene" group. 
```

#Test Tree
Upload the data "intelligent_tutor_new.csv". This is a data set of a differnt sample of students doing the same problems in the same system. We can use the tree we built for the previous data set to try to predict the "advice" we should give the teacher about these new students. 

```{r}
#Upload new data

D2 <- read.csv("intelligent_tutor_new.csv", header=TRUE)

#Generate predicted advice for new students based on tree generated from old students

D2$prediction <- predict(score_ctree, D2)

```

##Part III
Compare the predicted advice with the actual advice that these students recieved. What is the difference between the observed and predicted results?
```{r}
#If the model was perfect, it would say "no action" for all students due to their score of 1. In other words, everyone scored higher than 80%. 

table(D2$prediction)

```
```{r}
(no_action <- 116/nrow(D2)) # The model is correct 58% of the time
```

```{r}
(monitor <- 84/nrow(D2)) # The error rate of the model is 42%. 
# Another way to calculate: 1- no_action
```

```{r}
# Answer: For the observed results, it is supposed to say "no action" for all students since this dataset represents those students that scored higher than 80%, which is indicated by their score of 1. The model predicted the advice correctly 58% of the time. However, the error rate of the model is 42% percent since 42% of the time, the predicted advice was "monitor". This suggests that this regression tree is not overfitted. In other words, it is generalizable.   
```

